# -*- coding: utf-8 -*-
"""GeoAI Property Eval Streamlit App.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q0bTTW0YzxicNo4QCU2py-fHDFBIqfAe
"""

# GeoAI Property Evaluation Modernization (Demo)
# Streamlit app to fuse building footprints with cadastre for 1–2 blocks,
# compute simple draft parcel valuations, and preview on a web map.
# ---------------------------------------------------------------
# Features
#  - Upload building footprints (GeoJSON/GeoPackage/Shapefile .zip) and cadastre parcels
#  - Auto-CRS handling and geometry cleaning
#  - Assign buildings to parcels; compute building area & coverage (BCR)
#  - Adjustable valuation model (sliders): land value/㎡, building value/㎡, quality factor, tax rate
#  - Parcel-level valuation + revenue estimate
#  - Interactive map preview with parcel & building overlays
#  - Download CSV and GeoPackage outputs
#  - Optional synthetic sample data generator if you don’t have files yet
# ---------------------------------------------------------------

import io
import zipfile
from pathlib import Path

import numpy as np
import pandas as pd
import geopandas as gpd
from shapely.geometry import Polygon, Point
from shapely.ops import unary_union
import streamlit as st
from pyproj import CRS
import folium
from streamlit_folium import st_folium

# ---------------------------
# Utility functions
# ---------------------------
SUPPORTED_VECTORS = (".geojson", ".gpkg", ".json", ".shp", ".zip")


def _read_vector(file, layer=None):
    """Read vector data from uploaded file-like or path.
    - Accepts GeoJSON/GPKG directly; Shapefile must be a .zip of all parts.
    - Returns a GeoDataFrame.
    """
    name = file.name if hasattr(file, "name") else str(file)
    suffix = Path(name).suffix.lower()

    if suffix in (".geojson", ".json"):
        return gpd.read_file(file)
    if suffix == ".gpkg":
        return gpd.read_file(file, layer=layer)
    if suffix == ".zip":
        # Unzip to an in-memory buffer and read with fiona’s vsi
        zbytes = io.BytesIO(file.read() if hasattr(file, "read") else Path(file).read_bytes())
        with zipfile.ZipFile(zbytes) as zf:
            # find .shp
            shp_list = [n for n in zf.namelist() if n.lower().endswith(".shp")]
            if not shp_list:
                raise ValueError("ZIP does not contain a .shp file.")
            # Write to temp dir on disk because some GDAL builds require filesystem
            import tempfile, os
            tmpdir = tempfile.mkdtemp()
            zf.extractall(tmpdir)
            shp_path = None
            for n in shp_list:
                cand = Path(tmpdir) / n
                if cand.exists():
                    shp_path = cand
                    break
            if shp_path is None:
                raise ValueError("Could not locate .shp inside ZIP after extraction.")
            return gpd.read_file(shp_path)
    if suffix == ".shp":
        return gpd.read_file(file)
    raise ValueError(f"Unsupported vector format: {suffix}")


def _ensure_crs(gdf, fallback_epsg=4326):
    if gdf.crs is None:
        gdf = gdf.set_crs(epsg=fallback_epsg)
    return gdf


def _clean_geom(gdf):
    gdf = gdf[~gdf.geometry.is_empty & gdf.geometry.notnull()].copy()
    gdf["geometry"] = gdf.geometry.buffer(0)
    return gdf


def _project_for_area(gdf):
    """Project to a local equal-area projection for area metrics.
    If source CRS is geographic, approximate using EPSG:3857 for demo.
    (For production, pick a local UTM/Equal Area CRS.)
    """
    crs = CRS.from_user_input(gdf.crs)
    if crs.is_geographic:
        return gdf.to_crs(3857)
    return gdf


def _make_sample_data():
    """Create synthetic cadastre blocks and buildings for demo."""
    # base grid (two blocks)
    polys = []
    attrs = []
    start_x, start_y = 31.040, -17.830  # somewhere in Harare bbox approx
    block_w, block_h = 0.004, 0.003
    pid = 1
    for r in range(1):
        for c in range(2):
            x0 = start_x + c * block_w
            y0 = start_y + r * block_h
            poly = Polygon([(x0, y0), (x0+block_w, y0), (x0+block_w, y0+block_h), (x0, y0+block_h)])
            polys.append(poly)
            attrs.append({"parcel_id": f"P{pid:03d}", "block": f"B{c+1}", "land_use": "residential"})
            pid += 1
    parcels = gpd.GeoDataFrame(attrs, geometry=polys, crs="EPSG:4326")

    # buildings within parcels
    b_geoms = []
    b_attrs = []
    rng = np.random.default_rng(42)
    for i, row in parcels.iterrows():
        minx, miny, maxx, maxy = row.geometry.bounds
        for k in range(rng.integers(6, 12)):
            w = (maxx - minx) * rng.uniform(0.05, 0.12)
            h = (maxy - miny) * rng.uniform(0.05, 0.12)
            cx = rng.uniform(minx + w, maxx - w)
            cy = rng.uniform(miny + h, maxy - h)
            b = Polygon([
                (cx - w/2, cy - h/2), (cx + w/2, cy - h/2),
                (cx + w/2, cy + h/2), (cx - w/2, cy + h/2)
            ])
            b_geoms.append(b)
            b_attrs.append({"bld_id": f"B{i:02d}_{k:02d}", "floors": int(rng.integers(1, 3))})
    buildings = gpd.GeoDataFrame(b_attrs, geometry=b_geoms, crs="EPSG:4326")
    return parcels, buildings


# ---------------------------
# Streamlit UI
# ---------------------------
st.set_page_config(page_title="GeoAI Property Evaluation (Demo)", layout="wide")
st.title("GeoAI Property Evaluation Modernization — Demo App")
st.caption("Upload building footprints and cadastre for 1–2 blocks to create a draft valuation and revenue estimate. Built with Streamlit + GeoPandas.")

with st.sidebar:
    st.header("1) Data Inputs")
    st.write("Upload **Cadastre (Parcels)** and **Building Footprints**. Supported: GeoJSON, GPKG, Shapefile (.zip).")

    cad_file = st.file_uploader("Cadastre / Parcels", type=[s[1:] for s in SUPPORTED_VECTORS])
    bld_file = st.file_uploader("Building Footprints", type=[s[1:] for s in SUPPORTED_VECTORS])

    st.markdown("— or —")
    use_sample = st.checkbox("Use synthetic sample data (Harare demo)", value=(cad_file is None and bld_file is None))

    st.header("2) Valuation Model")
    st.write("Adjust basic parameters for a simple draft valuation. For production, replace with your council’s model.")
    land_val = st.number_input("Land value (USD per m²)", min_value=0.0, value=12.0, step=0.5)
    bld_val = st.number_input("Building value (USD per m² of footprint)", min_value=0.0, value=180.0, step=5.0)
    quality = st.slider("Quality/Condition factor", 0.5, 2.0, 1.0, step=0.05)
    tax_rate = st.slider("Illustrative rate (%) for revenue calc", 0.0, 15.0, 3.0, step=0.1)

    st.header("3) Options")
    dissolve_by_block = st.checkbox("Show per-block summaries (if 'block' field exists)")

# Read / generate data
if use_sample:
    parcels = None
    buildings = None
    try:
        parcels, buildings = _make_sample_data()
    except Exception as e:
        st.error(f"Sample data generation failed: {e}")
else:
    parcels = buildings = None

if parcels is None and cad_file is not None:
    try:
        parcels = _read_vector(cad_file)
    except Exception as e:
        st.error(f"Failed to read cadastre: {e}")

if buildings is None and bld_file is not None:
    try:
        buildings = _read_vector(bld_file)
    except Exception as e:
        st.error(f"Failed to read buildings: {e}")

if parcels is None or buildings is None:
    st.warning("Upload both cadastre and building footprints, or enable sample data in the sidebar.")
    st.stop()

# Ensure CRS & clean
parcels = _ensure_crs(_clean_geom(parcels))
buildings = _ensure_crs(_clean_geom(buildings), fallback_epsg=parcels.crs.to_epsg() or 4326)

# Harmonize CRS to parcels
if parcels.crs != buildings.crs:
    buildings = buildings.to_crs(parcels.crs)

# Compute parcel areas (m²)
parcels_area_crs = _project_for_area(parcels)
parcels_area = parcels_area_crs.copy()
parcels_area["parcel_area_m2"] = parcels_area.geometry.area
parcels = parcels.join(parcels_area[["parcel_area_m2"]])

# Assign buildings to parcels (spatial join)
try:
    b_in_p = gpd.sjoin(buildings, parcels.reset_index().rename(columns={"index": "_pidx"}), how="left", predicate="intersects")
except Exception:
    b_in_p = gpd.sjoin(buildings, parcels.reset_index().rename(columns={"index": "_pidx"}), how="left")

# Compute building areas
b_area_crs = _project_for_area(b_in_p)
b_in_p["bld_area_m2"] = b_area_crs.geometry.area

# Drop buildings with no parcel match
b_in_p = b_in_p.dropna(subset=["_pidx"]).copy()

# Aggregate buildings by parcel
parcel_id_col = None
for cand in ["parcel_id", "PARCEL_ID", "ParcelID", "PARCEL", "ID", "id"]:
    if cand in parcels.columns:
        parcel_id_col = cand
        break
if parcel_id_col is None:
    parcel_id_col = "_pidx"  # fallback index-based id

agg = b_in_p.groupby("_pidx").agg(
    bld_count=("geometry", "count"),
    bld_area_m2=("bld_area_m2", "sum")
).reset_index()

parcels_eval = parcels.reset_index().merge(agg, how="left", left_on="index", right_on="_pidx").drop(columns=["_pidx"])
parcels_eval["bld_count"] = parcels_eval["bld_count"].fillna(0).astype(int)
parcels_eval["bld_area_m2"] = parcels_eval["bld_area_m2"].fillna(0.0)
parcels_eval["bcr"] = np.where(parcels_eval["parcel_area_m2"] > 0, parcels_eval["bld_area_m2"] / parcels_eval["parcel_area_m2"], 0)

# Simple valuation model
parcels_eval["land_value_usd"] = parcels_eval["parcel_area_m2"] * land_val
parcels_eval["building_value_usd"] = parcels_eval["bld_area_m2"] * bld_val * quality
parcels_eval["total_value_usd"] = parcels_eval["land_value_usd"] + parcels_eval["building_value_usd"]
parcels_eval["est_revenue_usd"] = parcels_eval["total_value_usd"] * (tax_rate / 100.0)

# ---------------------------
# Layout: Map + Tables
# ---------------------------
col_map, col_tbl = st.columns([1.2, 1.0], gap="large")

with col_map:
    st.subheader("Map Preview")
    # Create a folium map centered on parcels
    center = parcels_eval.to_crs(4326).geometry.unary_union.centroid
    m = folium.Map(location=[center.y, center.x], zoom_start=16, control_scale=True)

    # Parcels layer
    folium.GeoJson(
        parcels_eval.to_crs(4326).drop(columns=[c for c in parcels_eval.columns if c == "geometry"]).merge(
            parcels_eval[["geometry"]].to_crs(4326), left_index=True, right_index=True
        ),
        name="Parcels",
        style_function=lambda x: {"fillColor": "#00000000", "color": "#2b8a3e", "weight": 1.5},
        tooltip=folium.features.GeoJsonTooltip(fields=[parcel_id_col, "parcel_area_m2", "bld_count", "bld_area_m2", "bcr", "total_value_usd"], aliases=["Parcel ID", "Area (m²)", "Bldgs", "Bldg area (m²)", "BCR", "Total value (USD)"], localize=True)
    ).add_to(m)

    # Buildings layer
    folium.GeoJson(
        b_in_p.to_crs(4326),
        name="Buildings",
        style_function=lambda x: {"fillColor": "#1f77b4", "color": "#1f77b4", "weight": 0.8, "fillOpacity": 0.5},
        tooltip=folium.features.GeoJsonTooltip(fields=["bld_id", "bld_area_m2"], aliases=["Building", "Footprint (m²)"])
    ).add_to(m)

    folium.LayerControl(collapsed=False).add_to(m)

    st_data = st_folium(m, height=520, use_container_width=True)

with col_tbl:
    st.subheader("Parcel Valuation — Draft")
    show_cols = [parcel_id_col, "parcel_area_m2", "bld_count", "bld_area_m2", "bcr", "land_value_usd", "building_value_usd", "total_value_usd", "est_revenue_usd"]
    show_cols = [c for c in show_cols if c in parcels_eval.columns]
    st.dataframe(parcels_eval[show_cols].sort_values("total_value_usd", ascending=False), use_container_width=True, height=520)

# Block summaries (optional)
if dissolve_by_block and "block" in parcels_eval.columns:
    st.subheader("Block Summary")
    block_df = parcels_eval.groupby("block").agg(
        parcels=(parcel_id_col, "count"),
        area_m2=("parcel_area_m2", "sum"),
        bld_area_m2=("bld_area_m2", "sum"),
        total_value_usd=("total_value_usd", "sum"),
        est_revenue_usd=("est_revenue_usd", "sum")
    ).reset_index()
    st.dataframe(block_df, use_container_width=True)

# ---------------------------
# Downloads
# ---------------------------
st.subheader("Download Outputs")

# Tabular CSV
csv_buf = io.StringIO()
parcels_eval.drop(columns=["index"], errors="ignore").to_csv(csv_buf, index=False)
st.download_button("Download Parcel Valuations (CSV)", csv_buf.getvalue(), file_name="parcel_valuations.csv", mime="text/csv")

# GeoPackage with parcels + buildings
try:
    gpkg_buf = io.BytesIO()
    with zipfile.ZipFile(gpkg_buf, mode="w", compression=zipfile.ZIP_DEFLATED) as zf:
        # Write to a temp gpkg on disk then zip with a csv for convenience
        import tempfile
        tmpdir = tempfile.mkdtemp()
        gpkg_path = Path(tmpdir) / "geoai_eval.gpkg"
        parcels_eval.to_file(gpkg_path, layer="parcels_eval", driver="GPKG")
        b_in_p.to_file(gpkg_path, layer="buildings", driver="GPKG")
        zf.write(gpkg_path, arcname="geoai_eval.gpkg")
    st.download_button("Download GeoPackage (parcels + buildings)", gpkg_buf.getvalue(), file_name="geoai_eval_gpkg.zip")
except Exception as e:
    st.info("GeoPackage export may fail on limited environments. If so, export the CSV and map from your desktop run.")

# ---------------------------
# Notes & Next Steps
# ---------------------------
st.markdown(
    """
**Notes (Demo):**
- Area calcs use EPSG:3857 as a simple approximation when source CRS is geographic. For production, switch to local UTM / equal-area.
- Replace the valuation sliders with your council’s actual model (depreciation, construction type, age, zoning, frontage, storeys, etc.).
- If using Shapefiles, upload a **.zip** containing .shp, .shx, .dbf, .prj.

**Next Steps:**
1. Add a parcel-to-owner lookup (if you have an owner register) for notice generation.
2. Add multi-ward aggregation and a revenue uplift dashboard.
3. Hook into HWATA inference API to auto-generate buildings from aerials when footprints are missing.
    """
)